{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"extendedCNN_multi.ipynb","provenance":[{"file_id":"1JDfeQ3RmsOa4xSUjcltuhSk_jgpzfq-p","timestamp":1618284212496},{"file_id":"1mBRixlK_v5KuB66nblNmd_W5Vr7AYbbD","timestamp":1617241243936}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Ou2K05Vy0j85"},"source":["Torch is already installed in Colab - but you can run for fun to check"]},{"cell_type":"code","metadata":{"id":"WNZPiG740iuv"},"source":["#!pip3 install torch"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6kRNbOEu0JZr"},"source":["Add the DLH folder in the top-level of your Google Drive\n","Mount Colab to this location (only run once)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Mo1fusYy3nl","executionInfo":{"status":"ok","timestamp":1619834090229,"user_tz":360,"elapsed":1570,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"7b0fac16-941f-4412-a49e-c613617ad06b"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)\n","os.chdir(\"drive/My Drive/DLH_Project\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Jv-v89J1YSng","executionInfo":{"status":"ok","timestamp":1619834094223,"user_tz":360,"elapsed":467,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"278daa1e-a297-4344-953c-cdb4b6270f00"},"source":["%pwd"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/.shortcut-targets-by-id/1vmmLQvXIsZR9fm3bw0w0w0S4STu7QfhY/DLH_Project'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"IQQ2CQ-40WCg"},"source":["Check that we are in the DLH_Project folder"]},{"cell_type":"markdown","metadata":{"id":"x1EoMHCB10mo"},"source":["Load the necessary modules\n"]},{"cell_type":"code","metadata":{"id":"HG88fHmd164T"},"source":["import pandas as pd\n","import torch\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","from skimage import io, transform\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GyvDTiZsar7h"},"source":["IMG_PATH =  '/content/drive/MyDrive/DLH_Project/images/'\n","TRAIN_CSV = '/content/drive/My Drive/DLH_Project/images/lateral_multi_train.csv'  #input your train.csv file here\n","VALID_CSV = '/content/drive/MyDrive/DLH_Project/images/lateral_multi_test.csv'   #input your valid.csv file here\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"twNLamTM1_L7"},"source":["Create custom dataset for loading images from the filepaths specified in the CSV"]},{"cell_type":"code","metadata":{"id":"aj2NY5RoWCHH"},"source":["df_train = pd.read_csv(TRAIN_CSV, header='infer')\n","df_test = pd.read_csv(VALID_CSV, header='infer')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aWF45REEZZMJ","executionInfo":{"status":"ok","timestamp":1619834105457,"user_tz":360,"elapsed":498,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"dc0b3e5b-2272-4ba0-b859-9d7ac53d5cf1"},"source":["df_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2473, 20)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Qqv5fYPPmdU","executionInfo":{"status":"ok","timestamp":1619834107030,"user_tz":360,"elapsed":423,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"0892351d-1c64-48fa-ffa6-c5c46352da79"},"source":["del df_train['Unnamed: 0']\n","for k in range(5,19):\n","  print(df_train.columns[k], '\\t\\t', df_train.iloc[:,k].sum(), 'positive labels')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["No Finding \t\t 453.0 positive labels\n","Enlarged Cardiomediastinum \t\t 129.0 positive labels\n","Cardiomegaly \t\t 258.0 positive labels\n","Lung Opacity \t\t 841.0 positive labels\n","Lung Lesion \t\t 159.0 positive labels\n","Edema \t\t 159.0 positive labels\n","Consolidation \t\t 121.0 positive labels\n","Pneumonia \t\t 110.0 positive labels\n","Atelectasis \t\t 269.0 positive labels\n","Pneumothorax \t\t 126.0 positive labels\n","Pleural Effusion \t\t 652.0 positive labels\n","Pleural Other \t\t 89.0 positive labels\n","Fracture \t\t 121.0 positive labels\n","Support Devices \t\t 649.0 positive labels\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":316},"id":"aiW22W5RSWD9","executionInfo":{"status":"ok","timestamp":1619834111214,"user_tz":360,"elapsed":510,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"c5c3e6f1-b8dc-4227-864b-6412012c6929"},"source":["df_train.head(n=5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Path</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>Frontal/Lateral</th>\n","      <th>AP/PA</th>\n","      <th>No Finding</th>\n","      <th>Enlarged Cardiomediastinum</th>\n","      <th>Cardiomegaly</th>\n","      <th>Lung Opacity</th>\n","      <th>Lung Lesion</th>\n","      <th>Edema</th>\n","      <th>Consolidation</th>\n","      <th>Pneumonia</th>\n","      <th>Atelectasis</th>\n","      <th>Pneumothorax</th>\n","      <th>Pleural Effusion</th>\n","      <th>Pleural Other</th>\n","      <th>Fracture</th>\n","      <th>Support Devices</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CheXpert-v1.0-small/train/patient00221/study9/...</td>\n","      <td>Female</td>\n","      <td>46</td>\n","      <td>Lateral</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CheXpert-v1.0-small/train/patient09293/study4/...</td>\n","      <td>Male</td>\n","      <td>27</td>\n","      <td>Lateral</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>CheXpert-v1.0-small/train/patient08368/study2/...</td>\n","      <td>Male</td>\n","      <td>67</td>\n","      <td>Lateral</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CheXpert-v1.0-small/train/patient08817/study1/...</td>\n","      <td>Male</td>\n","      <td>54</td>\n","      <td>Lateral</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>CheXpert-v1.0-small/train/patient03903/study1/...</td>\n","      <td>Female</td>\n","      <td>45</td>\n","      <td>Lateral</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                Path  ... Support Devices\n","0  CheXpert-v1.0-small/train/patient00221/study9/...  ...             0.0\n","1  CheXpert-v1.0-small/train/patient09293/study4/...  ...             1.0\n","2  CheXpert-v1.0-small/train/patient08368/study2/...  ...             1.0\n","3  CheXpert-v1.0-small/train/patient08817/study1/...  ...             0.0\n","4  CheXpert-v1.0-small/train/patient03903/study1/...  ...             0.0\n","\n","[5 rows x 19 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BdTfvXyWo8FM","executionInfo":{"status":"ok","timestamp":1619671183397,"user_tz":360,"elapsed":170,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"f488b7d6-bd7a-4b02-fc02-71d2eea8a390"},"source":["df_test.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(315, 20)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Glt2xyP5GIEt","executionInfo":{"status":"ok","timestamp":1619834141564,"user_tz":360,"elapsed":356,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"f79e8f78-0350-4fb2-f08b-b8ce4667d289"},"source":["del df_test['Unnamed: 0']\n","for k in range(5,19):\n","  print(df_test.columns[k], '\\t\\t', df_test.iloc[:,k].sum(), 'positive labels')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["No Finding \t\t 59.0 positive labels\n","Enlarged Cardiomediastinum \t\t 17.0 positive labels\n","Cardiomegaly \t\t 33.0 positive labels\n","Lung Opacity \t\t 99.0 positive labels\n","Lung Lesion \t\t 27.0 positive labels\n","Edema \t\t 20.0 positive labels\n","Consolidation \t\t 9.0 positive labels\n","Pneumonia \t\t 11.0 positive labels\n","Atelectasis \t\t 26.0 positive labels\n","Pneumothorax \t\t 17.0 positive labels\n","Pleural Effusion \t\t 88.0 positive labels\n","Pleural Other \t\t 13.0 positive labels\n","Fracture \t\t 16.0 positive labels\n","Support Devices \t\t 96.0 positive labels\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l-S7PLpT2DzJ"},"source":["from torch.utils.data import Dataset \n","\n","class PneumoniaDataset(Dataset): \n","  def __init__(self, csv_file, root_dir, transform = None): \n","     \n","    df = pd.read_csv(csv_file, header='infer')\n","    del df['Unnamed: 0']\n","    for i in range(len(df)):\n","      if df.iloc[i, 1]=='Male':\n","        df.iloc[i,1] = 0\n","      else:\n","        df.iloc[i,1] = 1 \n","    #print(df.head(5))\n","    self.data_file = df\n","    self.max = df.iloc[:,2].max()\n","    self.min = df.iloc[:,2].min()\n","    self.root_dir = root_dir  #not being used since full path is given in my code\n","    self.transform = transform\n","\n","  def __len__(self):\n","    return(len(self.data_file))\n","\n","  def __getitem__(self, idx): \n","    path = self.data_file\n","    #img_path = os.path.join(self.root_dir, self.data_file.iloc[idx, 0])\n","    \n","    img_path_L = IMG_PATH + self.data_file.iloc[idx, 0]\n","    img_path_F = IMG_PATH + self.data_file.iloc[idx, 0].strip('2_lateral.jpg') + '1_frontal.jpg'  #also get the frontal image\n","    image_l = io.imread(img_path_L)\n","    image_f = io.imread(img_path_F)\n","\n","    if self.transform:\n","      image_l = self.transform(image_l)  #this self.transform is an object of a class transforms.Compose()\n","      image_f = self.transform(image_f)\n","    image = torch.cat((image_f, image_l), dim=0) \n","    norm_data = (self.data_file.iloc[idx,2] - self.min)/(self.max - self.min)\n","    ehr_data = [self.data_file.iloc[idx, 1], norm_data]\n","    ehr_data = np.array(ehr_data, dtype='float')\n","    ehr_data = torch.tensor(ehr_data, dtype=torch.float32)\n","    ehr = ehr_data\n","\n","    y = self.data_file.iloc[idx, 5:19]  #important!!! change y for multilabel classification\n","    y = np.array(y, dtype='float')\n","    y = torch.tensor(y, dtype = torch.float32)  #dont forget to change y to tensor; long is required for loss calculation see https://jdhao.github.io/2017/11/15/pytorch-datatype-note/\n","    return image, ehr, y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"UBGwMjlAN6Sl","executionInfo":{"status":"ok","timestamp":1618861894981,"user_tz":360,"elapsed":3435,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"a6017ac5-81cf-4935-ac92-6500128812d4"},"source":["'''\n","dataset = PneumoniaDataset(csv_file=TRAIN_CSV, root_dir=\"images/\", transform=transforms.ToTensor())  #root_dir not being used since full path is given in TRAIN_CSV\n","# using the ToTensor transform to grab image shape easily\n","\n","print(len(dataset))\n","for i in range(1):\n","  print(i, dataset[i])\n","  print(i, \"image shape: \", dataset[i][0].size())\n","'''  "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\ndataset = PneumoniaDataset(csv_file=TRAIN_CSV, root_dir=\"images/\", transform=transforms.ToTensor())  #root_dir not being used since full path is given in TRAIN_CSV\\n# using the ToTensor transform to grab image shape easily\\n\\nprint(len(dataset))\\nfor i in range(1):\\n  print(i, dataset[i])\\n  print(i, \"image shape: \", dataset[i][0].size())\\n'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"vGs9DS-U3ljc"},"source":["Dataloader\n"]},{"cell_type":"code","metadata":{"id":"2pZn7-6p_0qa"},"source":["def load_data(csv_filepath, root_dir):\n","  img_transform = transforms.Compose([\n","  transforms.ToTensor(),\n","  transforms.RandomResizedCrop(224)\n","  ])\n","  train_data = PneumoniaDataset(csv_filepath, root_dir, transform = img_transform) \n","  train_loader = torch.utils.data.DataLoader(train_data, batch_size = 32, shuffle = True) \n","  return train_loader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QbziA9EcAiiB"},"source":["train_loader = load_data(TRAIN_CSV, root_dir=\"images/\")  #root_dir not being used since full path is given in TRAIN_CSV\n","valid_loader = load_data(VALID_CSV, root_dir=\"images/\")  #root_dir not being used since full path is given in VALID_CSV"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2SRYCQJLdDsR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619671362510,"user_tz":360,"elapsed":161532,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"d72b9017-9122-4a68-b570-0c092fd536fa"},"source":["#sanity checks\n","\n","data = iter(train_loader)\n","data_batch1 = next(data)\n","print(data_batch1[1].shape)  #shape looks right\n","#print(data_batch1[0][0])  #data of 1st sample (1,224,224)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([32, 2])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RiVqKGU3q8wd","executionInfo":{"status":"ok","timestamp":1619671394795,"user_tz":360,"elapsed":189920,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"61d4b747-1cd3-43d6-86e3-d72b61c1ee9f"},"source":["#sanity checks\n","data = iter(valid_loader)\n","data_batch1 = next(data)\n","print(data_batch1[0].shape)  #shape looks right\n","print(data_batch1[0][0])  #data of 1st sample (1,224,224)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([32, 2, 224, 224])\n","tensor([[[0.1765, 0.1898, 0.2127,  ..., 0.1708, 0.1686, 0.1686],\n","         [0.1668, 0.1812, 0.2017,  ..., 0.1660, 0.1737, 0.1808],\n","         [0.1636, 0.1740, 0.1880,  ..., 0.1692, 0.1737, 0.1768],\n","         ...,\n","         [0.2745, 0.2747, 0.2656,  ..., 0.2952, 0.2814, 0.2627],\n","         [0.2260, 0.2371, 0.2451,  ..., 0.2777, 0.2810, 0.2806],\n","         [0.2235, 0.2311, 0.2425,  ..., 0.2364, 0.2474, 0.2588]],\n","\n","        [[0.1451, 0.1451, 0.1472,  ..., 0.5853, 0.1023, 0.1036],\n","         [0.1431, 0.1451, 0.1472,  ..., 0.5517, 0.0804, 0.1007],\n","         [0.1412, 0.1426, 0.1472,  ..., 0.5555, 0.0836, 0.1007],\n","         ...,\n","         [0.8573, 0.8239, 0.8185,  ..., 0.0466, 0.0629, 0.0842],\n","         [0.8321, 0.8320, 0.8177,  ..., 0.0457, 0.0617, 0.0842],\n","         [0.8172, 0.8045, 0.8184,  ..., 0.0485, 0.0617, 0.0842]]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Vw7f7k8YGAFG"},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleCNN, self).__init__()\n","        \n","        self.w = 224  #width and height of image\n","        self.conv1 = nn.Conv2d(2, 6, 5, 2)  #(input=2, output, kernel size, stride)\n","        self.w2 = (self.w - 5)//2 + 1\n","        self.pool = nn.MaxPool2d(2, 2)  #(kernel size, stride)\n","        self.w2p = (self.w2 - 2)//2 + 1\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.w3 = (self.w2p - 5)//1 + 1\n","        self.w3p = (self.w3 - 2)//2 +1\n","        self.fc1 = nn.Linear(16 * self.w3p * self.w3p + 2, 120) \n","        self.dropout = nn.Dropout(p=0.5)\n","        self.fc2 = nn.Linear(120, 60)\n","        self.fc3 = nn.Linear(60, 14)  #change output to 14 \n","        self.sigmoid = nn.Sigmoid()\n","        \n","        \n","\n","    def forward(self, image, ehr):\n","        #input is of shape (batch_size=32, 1, 224, 224) if you did the dataloader right\n","        x = image\n","        x = F.relu(self.conv1(x))\n","        x = self.pool(x)\n","        x = F.relu(self.conv2(x))\n","        x = self.pool(x)\n","        x = x.view(-1, 16 * self.w3p * self.w3p)  #check\n","        x = torch.cat((x, ehr), dim=1)  #cat the ehr data with conv data\n","        x = F.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = F.relu(self.fc2(x))\n","        x = self.dropout(x)\n","        x = self.fc3(x)\n","        x = self.sigmoid(x)  #output will be (batchsize, 14)\n","\n","        #print('output shape = ', x.shape)\n","        return x\n","\n","model = SimpleCNN()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k6BHzJyIpgu3"},"source":["#print(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Woi6SJnXatus"},"source":["#define optimizer and loss function\n","import torch.optim as optim\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr= 0.001)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ZhYNlVnbAWY"},"source":["\n","def train_model(model, train_loader, valid_loader, n_epoch, optimizer=optimizer, criterion=criterion):\n","    import torch.optim as optim\n","\n","    model.train() # prep model for training\n","    \n","    \n","    for epoch in range(n_epoch):\n","        curr_epoch_loss = []\n","        for image, ehr, target in train_loader:\n","                       \n","            optimizer.zero_grad()\n","\n","            y_hat = model(image, ehr)  #forward pass\n","            y_hat = torch.squeeze(y_hat, dim=1)  #shape is (batch#, 14)\n","            #print('y_hat shape = ', y_hat.shape)\n","            #y_hat = torch.tensor(y_hat, dtype=torch.float32, requires_grad=True)  #chech on this: what is requires_grad=True\n","            \n","            #print('target dtype = ',target.type())\n","            #print('yhat dtype = ',y_hat.type())\n","            loss = criterion(y_hat, target)  #loss calculation          \n","            \n","            \"\"\" backward pass \"\"\"\n","            loss.backward()\n","            \"\"\" optimization \"\"\"\n","            optimizer.step()   \n","            \n","            curr_epoch_loss.append(loss.cpu().data.numpy()) \n","        print(f\"Epoch {epoch}: curr_epoch_loss={np.mean(curr_epoch_loss)}\")\n","        #evaluate(model, valid_loader)\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oF08FnAnphJy"},"source":["from sklearn.metrics import *\n","\n","def classification_metrics02(Y_pred, Y_true):\n","    #input: both Y_pred (predicted probabilites), Y_true (truth labels) are numpy arrays (n,14) for multilabel classification\n","    #output: dataframe shape (14, 5) -> 14 labels, 5 metrics \n","\n","    Y_pred_prob = Y_pred        \n","    Y_pred_label = Y_pred > 0.5  #boolean dtype\n","    Y_true = Y_true > 0          #boolean dtype\n","\n","    #print(Y_pred_prob)\n","    #print(Y_pred_label)\n","    #print(Y_true)\n","\n","    Y_pred_prob = np.transpose(Y_pred_prob)\n","    Y_pred_label = np.transpose(Y_pred_label)\n","    Y_true = np.transpose(Y_true)\n","    num_labels = Y_true.shape[0]\n","    results = []\n"," \n","    for i in range(num_labels):\n","      scores = []\n","      #to prevent auc throwing an error, assign to 'nan' for the condition below:\n","      if Y_true[i,:].sum() == 0 or Y_true[i,:].sum() == Y_true.shape[1]: \n","        auc = np.NAN\n","      else:\n","        auc = roc_auc_score(Y_true[i,:], Y_pred_prob[i,:])  \n","\n","      acc = accuracy_score(Y_true[i,:], Y_pred_label[i,:])\n","      precision = precision_score(Y_true[i,:], Y_pred_label[i,:], average='binary')\n","      recall = recall_score(Y_true[i,:], Y_pred_label[i,:], average='binary')\n","      f1score = f1_score(Y_true[i,:], Y_pred_label[i,:], average='binary')\n","\n","      scores = [acc, auc, precision, recall, f1score]\n","      results.append(scores)\n","    #print(results)\n","    results = np.array(results)\n","    metrics_df = pd.DataFrame(results,columns=['accuracy', 'auc', 'precision', 'recall', 'f1'])\n","    return metrics_df\n","\n","#input: model, loader\n","def evaluate02(model, valid_loader):\n","    model.eval()\n","    all_y_true = torch.FloatTensor()  #this will accumulate all batches; is it faster to use numpy matrix?\n","    all_y_hat = torch.FloatTensor()   #this will accumulate all batches\n","    \n","    for image, ehr, y_val in valid_loader:\n","        y_hat = model(image, ehr)\n","        # y_hat shape is [batch size, 14] \n","        #y_hat = y_hat.view(y_hat.shape[0])  \n","        \n","        all_y_hat = torch.cat((all_y_hat, y_hat.to('cpu').float()), dim=0)\n","        all_y_true = torch.cat((all_y_true,  y_val.to('cpu').float()), dim=0) \n","    \n","    all_y_hat = all_y_hat.detach().numpy()\n","    all_y_true = all_y_true.detach().numpy()\n","    #print(type(all_y_true))   \n","    #print(type(all_y_hat))\n","    metrics = classification_metrics02(all_y_hat, all_y_true)\n","    print(metrics)\n","    #print(f\"acc: {acc:.3f}, precision: {precision:.3f}, recall: {recall:.3f}, f1: {f1:.3f}\")\n","    return "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tt5nofYkLMEt","executionInfo":{"status":"ok","timestamp":1619837976313,"user_tz":360,"elapsed":3683410,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"dc222384-9d48-4263-d8f0-fe2b0d1e6f2c"},"source":["train_model(model, train_loader, valid_loader, n_epoch=5, optimizer=optimizer, criterion=criterion)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 0: curr_epoch_loss=0.4172011613845825\n","Epoch 1: curr_epoch_loss=0.35445281863212585\n","Epoch 2: curr_epoch_loss=0.34695181250572205\n","Epoch 3: curr_epoch_loss=0.3420909345149994\n","Epoch 4: curr_epoch_loss=0.34010377526283264\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SimpleCNN(\n","  (conv1): Conv2d(2, 6, kernel_size=(5, 5), stride=(2, 2))\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","  (fc1): Linear(in_features=10002, out_features=120, bias=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc2): Linear(in_features=120, out_features=60, bias=True)\n","  (fc3): Linear(in_features=60, out_features=14, bias=True)\n","  (sigmoid): Sigmoid()\n",")"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4mMRXEvdkH5H","executionInfo":{"status":"ok","timestamp":1619838394438,"user_tz":360,"elapsed":4093873,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"160ff226-65e7-4dbc-d58e-6226a897fe82"},"source":["evaluate02(model, valid_loader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["    accuracy       auc  precision  recall   f1\n","0   0.812698  0.461666        0.0     0.0  0.0\n","1   0.946032  0.646072        0.0     0.0  0.0\n","2   0.895238  0.528906        0.0     0.0  0.0\n","3   0.685714  0.562103        0.0     0.0  0.0\n","4   0.914286  0.458719        0.0     0.0  0.0\n","5   0.936508  0.546610        0.0     0.0  0.0\n","6   0.971429  0.606391        0.0     0.0  0.0\n","7   0.965079  0.471292        0.0     0.0  0.0\n","8   0.917460  0.533804        0.0     0.0  0.0\n","9   0.946032  0.676076        0.0     0.0  0.0\n","10  0.720635  0.652583        0.0     0.0  0.0\n","11  0.958730  0.408049        0.0     0.0  0.0\n","12  0.949206  0.479933        0.0     0.0  0.0\n","13  0.695238  0.592894        0.0     0.0  0.0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"R5wNMmgFHX6u"},"source":["#to save your model\n","#torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/simpleCNNplus_multi01.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p2WjhUFpfDB7"},"source":["model_multi00.pth - 20 epochs loss = 0.351   \n","\n"]},{"cell_type":"code","metadata":{"id":"2WQ9MLQtIKnl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619642705191,"user_tz":360,"elapsed":315,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"134a5490-4811-4076-ec26-63f7be127a46"},"source":["#to reload your model\n","modelmulti01 = SimpleCNN()  #create instance of your chosen model\n","modelmulti01.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/simpleCNNplus_multi01.pth'))\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"IIU6rk3hgbS2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619642717463,"user_tz":360,"elapsed":4894,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"690a3f1e-4581-4a18-bef2-27e77848d48e"},"source":["#run evaluate() on your saved model here to get statistics\n","evaluate02(modelmulti01, valid_loader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["    accuracy       auc  precision    recall        f1\n","0   0.809524  0.683925    0.00000  0.000000  0.000000\n","1   0.946032  0.644493    0.00000  0.000000  0.000000\n","2   0.895238  0.732646    0.00000  0.000000  0.000000\n","3   0.673016  0.570707    0.00000  0.000000  0.000000\n","4   0.914286  0.436986    0.00000  0.000000  0.000000\n","5   0.936508  0.623390    0.00000  0.000000  0.000000\n","6   0.971429  0.855846    0.00000  0.000000  0.000000\n","7   0.965079  0.477871    0.00000  0.000000  0.000000\n","8   0.917460  0.669417    0.00000  0.000000  0.000000\n","9   0.946032  0.663640    0.00000  0.000000  0.000000\n","10  0.742857  0.743342    0.62069  0.204545  0.307692\n","11  0.958730  0.484972    0.00000  0.000000  0.000000\n","12  0.949206  0.527174    0.00000  0.000000  0.000000\n","13  0.695238  0.581240    0.00000  0.000000  0.000000\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"PtnL2O_mepq_"},"source":[""],"execution_count":null,"outputs":[]}]}
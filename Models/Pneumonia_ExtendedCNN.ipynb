{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"extendedCNN_binary.ipynb","provenance":[{"file_id":"1JDfeQ3RmsOa4xSUjcltuhSk_jgpzfq-p","timestamp":1619469784428},{"file_id":"1mBRixlK_v5KuB66nblNmd_W5Vr7AYbbD","timestamp":1617241243936}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Ou2K05Vy0j85"},"source":["Torch is already installed in Colab - but you can run for fun to check"]},{"cell_type":"code","metadata":{"id":"WNZPiG740iuv"},"source":["#!pip3 install torch"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6kRNbOEu0JZr"},"source":["Add the DLH folder in the top-level of your Google Drive\n","Mount Colab to this location (only run once)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Mo1fusYy3nl","executionInfo":{"status":"ok","timestamp":1619833055955,"user_tz":360,"elapsed":1760,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"1eac1eee-f0e8-400a-d640-d44d3fb73790"},"source":["\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)\n","os.chdir(\"drive/My Drive/DLH_Project\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"_8RVGptFjuZL","executionInfo":{"status":"ok","timestamp":1619833055965,"user_tz":360,"elapsed":1758,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"2fed80f8-eb4e-4174-fe82-a416babe0117"},"source":["%pwd  #make sure you are in the DLH_Project file"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/.shortcut-targets-by-id/1vmmLQvXIsZR9fm3bw0w0w0S4STu7QfhY/DLH_Project'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"IQQ2CQ-40WCg"},"source":["Check that we are in the DLH_Project folder"]},{"cell_type":"markdown","metadata":{"id":"x1EoMHCB10mo"},"source":["Load the necessary modules\n"]},{"cell_type":"code","metadata":{"id":"HG88fHmd164T"},"source":["import pandas as pd\n","import torch\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","from skimage import io, transform\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"uorsJ_HoKiAH","executionInfo":{"status":"ok","timestamp":1619833058379,"user_tz":360,"elapsed":4156,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"99a9aa6b-3040-4c6c-a626-c9f14b4ca476"},"source":["torch.__version__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.8.1+cu101'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"GyvDTiZsar7h"},"source":["IMG_PATH =  '/content/drive/MyDrive/DLH_Project/images/'\n","TRAIN_CSV = '/content/drive/MyDrive/DLH_Project/images/lateral_train.csv'  #input your train.csv file here;  this data set does not contain same n as simple cnn model due to not enough images w lateral views\n","VALID_CSV = '/content/drive/MyDrive/DLH_Project/images/lateral_test2.csv'   #input your valid.csv file here; this data set has lateral views and was filtered to have the same number of pos and neg labels as simple cnn, resnet, densenet model for consistency "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":333},"id":"S-kGskSA74rA","executionInfo":{"status":"ok","timestamp":1619833058563,"user_tz":360,"elapsed":4324,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"1a06e7d5-a3c6-4acb-c202-233f879455f9"},"source":["#sanity check of training data file - not required to run\n","df_train = pd.read_csv(TRAIN_CSV, header='infer')\n","del df_train['Unnamed: 0'] #get rid of extraneous column\n","print(df_train.shape)\n","df_train.head(n=5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1082, 19)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Path</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>Frontal/Lateral</th>\n","      <th>AP/PA</th>\n","      <th>No Finding</th>\n","      <th>Enlarged Cardiomediastinum</th>\n","      <th>Cardiomegaly</th>\n","      <th>Lung Opacity</th>\n","      <th>Lung Lesion</th>\n","      <th>Edema</th>\n","      <th>Consolidation</th>\n","      <th>Pneumonia</th>\n","      <th>Atelectasis</th>\n","      <th>Pneumothorax</th>\n","      <th>Pleural Effusion</th>\n","      <th>Pleural Other</th>\n","      <th>Fracture</th>\n","      <th>Support Devices</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CheXpert-v1.0-small/train/patient00044/study6/...</td>\n","      <td>Female</td>\n","      <td>49</td>\n","      <td>Lateral</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CheXpert-v1.0-small/train/patient07169/study1/...</td>\n","      <td>Female</td>\n","      <td>44</td>\n","      <td>Lateral</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>CheXpert-v1.0-small/train/patient00901/study1/...</td>\n","      <td>Female</td>\n","      <td>29</td>\n","      <td>Lateral</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CheXpert-v1.0-small/train/patient04957/study3/...</td>\n","      <td>Male</td>\n","      <td>52</td>\n","      <td>Lateral</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>CheXpert-v1.0-small/train/patient00344/study1/...</td>\n","      <td>Male</td>\n","      <td>54</td>\n","      <td>Lateral</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                Path  ... Support Devices\n","0  CheXpert-v1.0-small/train/patient00044/study6/...  ...             1.0\n","1  CheXpert-v1.0-small/train/patient07169/study1/...  ...             0.0\n","2  CheXpert-v1.0-small/train/patient00901/study1/...  ...             0.0\n","3  CheXpert-v1.0-small/train/patient04957/study3/...  ...             0.0\n","4  CheXpert-v1.0-small/train/patient00344/study1/...  ...             0.0\n","\n","[5 rows x 19 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UaWkcYtRjiI3","executionInfo":{"status":"ok","timestamp":1619833058566,"user_tz":360,"elapsed":4319,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"16521ced-7667-4e9f-f1a0-ca4026ed8000"},"source":["df_train.iloc[:,12].sum()  #number of positive labels pneumonia"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["270.0"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":333},"id":"vYEF0x_t-9TI","executionInfo":{"status":"ok","timestamp":1619833058569,"user_tz":360,"elapsed":4312,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"992f2978-e209-47cf-d6d7-7bd1685d4e04"},"source":["#sanity check of validation file - not required to run\n","df_test = pd.read_csv(VALID_CSV, header='infer')\n","del df_test['Unnamed: 0']\n","print(df_test.shape)\n","df_test.head(n=5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(121, 19)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Path</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>Frontal/Lateral</th>\n","      <th>AP/PA</th>\n","      <th>No Finding</th>\n","      <th>Enlarged Cardiomediastinum</th>\n","      <th>Cardiomegaly</th>\n","      <th>Lung Opacity</th>\n","      <th>Lung Lesion</th>\n","      <th>Edema</th>\n","      <th>Consolidation</th>\n","      <th>Pneumonia</th>\n","      <th>Atelectasis</th>\n","      <th>Pneumothorax</th>\n","      <th>Pleural Effusion</th>\n","      <th>Pleural Other</th>\n","      <th>Fracture</th>\n","      <th>Support Devices</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CheXpert-v1.0-small/train/patient08164/study1/...</td>\n","      <td>Female</td>\n","      <td>55</td>\n","      <td>Lateral</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CheXpert-v1.0-small/train/patient05791/study3/...</td>\n","      <td>Male</td>\n","      <td>31</td>\n","      <td>Lateral</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>CheXpert-v1.0-small/train/patient06806/study1/...</td>\n","      <td>Male</td>\n","      <td>72</td>\n","      <td>Lateral</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CheXpert-v1.0-small/train/patient01448/study10...</td>\n","      <td>Female</td>\n","      <td>56</td>\n","      <td>Lateral</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>CheXpert-v1.0-small/train/patient09705/study1/...</td>\n","      <td>Male</td>\n","      <td>37</td>\n","      <td>Lateral</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                Path  ... Support Devices\n","0  CheXpert-v1.0-small/train/patient08164/study1/...  ...             0.0\n","1  CheXpert-v1.0-small/train/patient05791/study3/...  ...             0.0\n","2  CheXpert-v1.0-small/train/patient06806/study1/...  ...             0.0\n","3  CheXpert-v1.0-small/train/patient01448/study10...  ...             0.0\n","4  CheXpert-v1.0-small/train/patient09705/study1/...  ...             0.0\n","\n","[5 rows x 19 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0blajvEtkZSK","executionInfo":{"status":"ok","timestamp":1619833058570,"user_tz":360,"elapsed":4302,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"0e18fa4e-8165-48fa-91c6-4c94a568da44"},"source":["df_test.iloc[:,12].sum()  #number of positive labels "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["79.0"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"twNLamTM1_L7"},"source":["Create custom dataset for loading images from the filepaths specified in the CSV"]},{"cell_type":"code","metadata":{"id":"l-S7PLpT2DzJ"},"source":["from torch.utils.data import Dataset \n","\n","class PneumoniaDataset(Dataset): \n","  def __init__(self, csv_file, root_dir, transform = None): \n","\n","    df = pd.read_csv(csv_file, header='infer')\n","    del df['Unnamed: 0']  #get rid of unecessary column\n","    for i in range(len(df)):\n","      if df.iloc[i, 1]=='Male':\n","        df.iloc[i,1] = 0\n","      else:\n","        df.iloc[i,1] = 1  \n","    #df = self.filterDF(df, n=None)\n","    self.data_file = df\n","    self.max = df.iloc[:,2].max()\n","    self.min = df.iloc[:,2].min()\n","    self.root_dir = root_dir  #not being used since full path is given\n","    self.transform = transform\n","    \n","  def __len__(self):\n","    return(len(self.data_file))\n","\n","  def __getitem__(self, idx): \n","    path = self.data_file\n","    \n","    img_path_L = IMG_PATH + self.data_file.iloc[idx, 0]\n","    img_path_F = IMG_PATH + self.data_file.iloc[idx, 0].strip('2_lateral.jpg') + '1_frontal.jpg'  #also get the frontal image\n","\n","    image_l = io.imread(img_path_L)\n","    image_f = io.imread(img_path_F)\n","    if self.transform:\n","      image_l = self.transform(image_l)  #this self.transform is an object of a class transforms.Compose()\n","      image_f = self.transform(image_f)\n","    image = torch.cat((image_f, image_l), dim=0) \n","    norm_data = (self.data_file.iloc[idx,2] - self.min)/(self.max - self.min)\n","    ehr_data = [self.data_file.iloc[idx, 1], norm_data]\n","    ehr_data = np.array(ehr_data, dtype='float')\n","    ehr_data = torch.tensor(ehr_data, dtype=torch.float32)\n","    ehr = ehr_data\n","    y = self.data_file.iloc[idx, 12]  #important !!! column 12 is pneumonia\n","    y = np.array(y, dtype='float')\n","    y = torch.tensor(y, dtype = torch.float32)  #dont forget to change y to tensor; long is required for loss calculation see https://jdhao.github.io/2017/11/15/pytorch-datatype-note/\n","    return image, ehr, y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UBGwMjlAN6Sl","executionInfo":{"status":"ok","timestamp":1619833059129,"user_tz":360,"elapsed":4848,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"fff88d92-fe1a-4b81-e0be-b59b17b58050"},"source":["#sanity checks to see output of Dataset - not required to run\n","dataset = PneumoniaDataset(csv_file=TRAIN_CSV, root_dir=\"images/\", transform=transforms.ToTensor())  #root_dir not being used since full path is given in TRAIN_CSV\n","# using the ToTensor transform to grab image shape easily\n","\n","print(len(dataset))\n","for i in range(1):\n","  print(i, dataset[i])\n","  print(i, \"image shape: \", dataset[i][0].size())\n","  print(i, \"ehr shape: \", dataset[i][1].size())\n","  print(i, \"y shape: \", dataset[i][2].size())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1082\n","0 (tensor([[[0.1882, 0.1765, 0.1765,  ..., 0.1529, 0.1725, 0.2353],\n","         [0.2471, 0.2275, 0.2235,  ..., 0.0863, 0.0941, 0.1451],\n","         [0.1373, 0.1098, 0.0941,  ..., 0.0588, 0.0627, 0.0980],\n","         ...,\n","         [0.5176, 0.4745, 0.4078,  ..., 0.4784, 0.6275, 0.5608],\n","         [0.5490, 0.4980, 0.5294,  ..., 0.5608, 0.6353, 0.5373],\n","         [0.6039, 0.5647, 0.5294,  ..., 0.6471, 0.6431, 0.6706]],\n","\n","        [[0.3529, 0.3529, 0.3569,  ..., 0.1059, 0.1255, 0.1451],\n","         [0.3725, 0.3490, 0.3373,  ..., 0.0941, 0.1059, 0.1176],\n","         [0.3373, 0.3059, 0.2824,  ..., 0.0902, 0.0941, 0.0980],\n","         ...,\n","         [0.3608, 0.3451, 0.3216,  ..., 0.0000, 0.0000, 0.0000],\n","         [0.4039, 0.3765, 0.3373,  ..., 0.0000, 0.0000, 0.0000],\n","         [0.4824, 0.4314, 0.3765,  ..., 0.0000, 0.0000, 0.0000]]]), tensor([1.0000, 0.4306]), tensor(0.))\n","0 image shape:  torch.Size([2, 320, 320])\n","0 ehr shape:  torch.Size([2])\n","0 y shape:  torch.Size([])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vGs9DS-U3ljc"},"source":["Dataloader\n"]},{"cell_type":"code","metadata":{"id":"2pZn7-6p_0qa"},"source":["def load_data(csv_filepath, root_dir):\n","  img_transform = transforms.Compose([\n","  transforms.ToTensor(),\n","  transforms.RandomResizedCrop(224)\n","  ])\n","  train_data = PneumoniaDataset(csv_filepath, root_dir, transform = img_transform) \n","  train_loader = torch.utils.data.DataLoader(train_data, batch_size = 32, shuffle = True) \n","  return train_loader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QbziA9EcAiiB"},"source":["train_loader = load_data(TRAIN_CSV, root_dir=\"images/\")  #root_dir not being used since full path is given in TRAIN_CSV\n","valid_loader = load_data(VALID_CSV, root_dir=\"images/\")  #root_dir not being used since full path is given in VALID_CSV"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2SRYCQJLdDsR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619833060107,"user_tz":360,"elapsed":5810,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"a57814db-e0d5-48cd-ca4e-7262d2339aa7"},"source":["#sanity checks train_loader - not required to run\n","data = iter(train_loader)\n","data_batch1 = next(data)\n","print(data_batch1[0].shape)  #shape looks right\n","#print(data_batch1[0][0])  #data of 1st sample (2,224,224)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([32, 2, 224, 224])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RiVqKGU3q8wd","executionInfo":{"status":"ok","timestamp":1619833060583,"user_tz":360,"elapsed":6279,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"ed0b552f-27c5-400b-a093-7b4e3be485c1"},"source":["#sanity checks valid_loader - not required to run\n","data = iter(valid_loader)\n","data_batch1 = next(data)\n","print(data_batch1[1].shape)  #shape looks right (32,2)\n","#print(data_batch1[1])  #data of 1st sample (2,224,224)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([32, 2])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Vw7f7k8YGAFG"},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleCNN, self).__init__()\n","        \n","        self.w = 224  #width and height of image\n","        self.conv1 = nn.Conv2d(2, 16, 5, 2)  #(input=2, output, kernel size, stride)\n","        self.pool = nn.MaxPool2d(3,1)  #(kernel size, stride)\n","        self.norm2d_1 = nn.BatchNorm2d(16)  #batch normalization to prevent high gradients\n","        self.conv2 = nn.Conv2d(16, 32, 5)\n","        self.norm2d_2 = nn.BatchNorm2d(32)  \n","        self.conv3 = nn.Conv2d(32, 64, 5)\n","        self.norm2d_3 = nn.BatchNorm2d(64)  \n","        self.fc1 = nn.Linear(64 * 96 * 96 + 2, 120) #check input; include ehr data here!!!\n","        self.norm1d_1 = nn.BatchNorm1d(120)\n","        self.dropout = nn.Dropout(p=0.5)  #drop out layer to prevent overfitting\n","        self.fc2 = nn.Linear(120, 60)\n","        self.norm1d_2 = nn.BatchNorm1d(60)\n","        self.fc3 = nn.Linear(60, 1)  #change output to one for binary classification\n","        self.sigmoid = nn.Sigmoid()\n","        \n","    def forward(self, image, ehr):   \n","        \n","        x = F.leaky_relu(self.conv1(image))\n","        x = self.norm2d_1(x)\n","        x = self.pool(x)\n","        x = F.leaky_relu(self.conv2(x))\n","        x = self.norm2d_2(x)\n","        x = self.pool(x)\n","        x = F.leaky_relu(self.conv3(x))\n","        x = self.norm2d_3(x)\n","        x = self.pool(x)\n","        x = x.view(-1, 64*96*96)  #flatten and pass to nn.Linear     \n","        x= torch.cat((x, ehr), dim=1) #check! add ehr data here\n","        x = F.leaky_relu(self.fc1(x))\n","        x = self.norm1d_1(x)\n","        x = self.dropout(x)\n","        x = F.leaky_relu(self.fc2(x))\n","        x = self.norm1d_2(x)\n","        x = self.dropout(x)\n","        x = self.fc3(x)\n","        x = self.sigmoid(x)\n","        return x  \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k6BHzJyIpgu3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619833061593,"user_tz":360,"elapsed":7278,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"a6bce3b9-ae15-41dc-9b1b-2a4ea2cc452e"},"source":["model = SimpleCNN()\n","print(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["SimpleCNN(\n","  (conv1): Conv2d(2, 16, kernel_size=(5, 5), stride=(2, 2))\n","  (pool): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n","  (norm2d_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n","  (norm2d_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n","  (norm2d_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (fc1): Linear(in_features=589826, out_features=120, bias=True)\n","  (norm1d_1): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc2): Linear(in_features=120, out_features=60, bias=True)\n","  (norm1d_2): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (fc3): Linear(in_features=60, out_features=1, bias=True)\n","  (sigmoid): Sigmoid()\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Woi6SJnXatus"},"source":["#define the optimizer and loss function\n","import torch.optim as optim\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr= 0.001)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ZhYNlVnbAWY"},"source":["\n","def train_model(model, train_loader, valid_loader, n_epoch, optimizer=optimizer, criterion=criterion):\n","    import torch.optim as optim\n","\n","    model.train() # prep model for training\n","    \n","    \n","    for epoch in range(n_epoch):\n","        curr_epoch_loss = []\n","        for image, ehr, target in train_loader:  #image shape (32, 2, 224, 224), ehr (32, 2)\n","            \n","            optimizer.zero_grad()\n","\n","            y_hat = model(image, ehr)  #forward pass; model is of class SimpleCNN\n","            y_hat = torch.squeeze(y_hat, dim=1)\n","\n","            loss = criterion(y_hat, target)  #loss calculation          \n","            \n","            \"\"\" backward pass \"\"\"\n","            loss.backward()\n","            \"\"\" optimization \"\"\"\n","            optimizer.step()   \n","            \n","            curr_epoch_loss.append(loss.cpu().data.numpy()) \n","        print(f\"Epoch {epoch}: curr_epoch_loss={np.mean(curr_epoch_loss)}\")\n","        evaluate(model, valid_loader)\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ArfvXWf448ls"},"source":["from sklearn.metrics import *\n","\n","#input: Y_pred,Y_true\n","#output: accuracy, auc, precision, recall, f1-score\n","def classification_metrics(Y_pred, Y_true):\n","\n","    Y_pred_prob = Y_pred\n","    Y_pred_label = Y_pred > 0.5  #boolean dtype\n","    Y_true = Y_true > 0          #boolean dtype\n","    #print(Y_pred_prob)\n","    #print(Y_pred_label)\n","    #print(Y_true)\n","    acc, auc, precision, recall, f1score = accuracy_score(Y_true, Y_pred_label), \\\n","                                           roc_auc_score(Y_true, Y_pred), \\\n","                                           precision_score(Y_true, Y_pred_label), \\\n","                                           recall_score(Y_true, Y_pred_label), \\\n","                                           f1_score(Y_true, Y_pred_label)\n","    return acc, auc, precision, recall, f1score\n","\n","\n","#input: model, loader\n","def evaluate(model, valid_loader):\n","    model.eval()\n","    all_y_true = torch.FloatTensor()  #this will accumulate all batches\n","    all_y_hat = torch.FloatTensor()   #this will accumulate all batches\n","    \n","    for image, ehr, y_val in valid_loader:\n","        y_hat = model(image, ehr)\n","        # convert shape from [batch size, 1] to [batch size]\n","        y_hat = y_hat.view(y_hat.shape[0])\n","\n","        all_y_hat = torch.cat((all_y_hat, y_hat.to('cpu').float()), dim=0)\n","        all_y_true = torch.cat((all_y_true,  y_val.to('cpu').float()), dim=0) \n","    #all_y_hat[85] = 0.7  #just to test precision is working\n","    all_y_hat = all_y_hat.detach().numpy()\n","    all_y_true = all_y_true.detach().numpy()\n","    #print(type(all_y_true))   \n","    #print(type(all_y_hat))\n","    acc, auc, precision, recall, f1 = classification_metrics(all_y_hat, all_y_true)\n","    print(f\"acc: {acc:.3f}, auc: {auc:.3f}, precision: {precision:.3f}, recall: {recall:.3f}, f1: {f1:.3f}\")\n","    return acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tt5nofYkLMEt","executionInfo":{"status":"ok","timestamp":1619835153690,"user_tz":360,"elapsed":2099358,"user":{"displayName":"Steven Su","photoUrl":"","userId":"02523973797754475638"}},"outputId":"08ff1534-ad1e-4339-8e9c-fd53003cef4a"},"source":["train_model(model, train_loader, valid_loader, n_epoch=10, optimizer=optimizer, criterion=criterion)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 0: curr_epoch_loss=0.7031439542770386\n","acc: 0.421, auc: 0.480, precision: 0.737, recall: 0.177, f1: 0.286\n","Epoch 1: curr_epoch_loss=0.5766517519950867\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["acc: 0.347, auc: 0.460, precision: 0.000, recall: 0.000, f1: 0.000\n","Epoch 2: curr_epoch_loss=0.5717049837112427\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["acc: 0.347, auc: 0.594, precision: 0.000, recall: 0.000, f1: 0.000\n","Epoch 3: curr_epoch_loss=0.5649038553237915\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["acc: 0.347, auc: 0.559, precision: 0.000, recall: 0.000, f1: 0.000\n","Epoch 4: curr_epoch_loss=0.5671100616455078\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["acc: 0.347, auc: 0.602, precision: 0.000, recall: 0.000, f1: 0.000\n","Epoch 5: curr_epoch_loss=0.5651189684867859\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["acc: 0.347, auc: 0.586, precision: 0.000, recall: 0.000, f1: 0.000\n","Epoch 6: curr_epoch_loss=0.562197744846344\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["acc: 0.347, auc: 0.471, precision: 0.000, recall: 0.000, f1: 0.000\n","Epoch 7: curr_epoch_loss=0.5610071420669556\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["acc: 0.347, auc: 0.533, precision: 0.000, recall: 0.000, f1: 0.000\n","Epoch 8: curr_epoch_loss=0.5651713013648987\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["acc: 0.347, auc: 0.575, precision: 0.000, recall: 0.000, f1: 0.000\n","Epoch 9: curr_epoch_loss=0.5636739134788513\n","acc: 0.347, auc: 0.536, precision: 0.000, recall: 0.000, f1: 0.000\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["SimpleCNN(\n","  (conv1): Conv2d(2, 16, kernel_size=(5, 5), stride=(2, 2))\n","  (pool): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n","  (norm2d_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n","  (norm2d_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n","  (norm2d_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (fc1): Linear(in_features=589826, out_features=120, bias=True)\n","  (norm1d_1): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc2): Linear(in_features=120, out_features=60, bias=True)\n","  (norm1d_2): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (fc3): Linear(in_features=60, out_features=1, bias=True)\n","  (sigmoid): Sigmoid()\n",")"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"R5wNMmgFHX6u"},"source":["#to save your model\n","#torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/CNN_plus1.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2WQ9MLQtIKnl"},"source":["#to reload your model\n","#model0 = SimpleCNN()\n","#model0.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/CNN_plus1.pth'))\n"],"execution_count":null,"outputs":[]}]}